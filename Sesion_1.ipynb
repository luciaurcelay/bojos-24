{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPRKSlh97xpY"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_circles, make_classification, make_regression\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "io1qqJsG7xpc"
   },
   "source": [
    "### Funciones Auxiliares\n",
    "\n",
    "Usaremos estas funciones para ver los resultados de nuestros experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UWef931l7xpc"
   },
   "outputs": [],
   "source": [
    "def pintar_datos_clasificacion(X_train, y_train, X_test, y_test):\n",
    "    sns.scatterplot(x=X_train[:,0], y=X_train[:, 1], hue=y_train, marker='o', palette=['c','y'], s=80, label='train', legend=False)\n",
    "    sns.scatterplot(x=X_test[:,0], y=X_test[:, 1], hue=y_test, marker='*', palette=['c','y'], s=200, label='test', legend=False)\n",
    "    circle = mlines.Line2D([], [], linestyle='None', color='black', marker='o', label='train', markersize=7)\n",
    "    star = mlines.Line2D([], [], linestyle='None', color='black', marker='*', label='test', markersize=7)\n",
    "    legend1 = plt.legend(title='Particiones', handles=[circle, star], loc=1)\n",
    "    class_0 = mlines.Line2D([], [], color='c', marker='s', linestyle='None', markersize=7, label='0')\n",
    "    class_1 = mlines.Line2D([], [], color='y', marker='s', linestyle='None', markersize=7, label='1')\n",
    "    legend2 = plt.legend(title='Clases', handles=[class_0, class_1], loc=2)\n",
    "    plt.gca().add_artist(legend1)\n",
    "    plt.title('Train and test split');\n",
    "    \n",
    "    \n",
    "def pintar_resultados_regresion(X,y_real, X_train,y_train_pred,X_test,y_test_pred):\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=X_train,y=y_train, marker='o', color='c', edgecolor='none', s=80, label = 'Valores de train');\n",
    "    index_train = np.argsort(X_train)\n",
    "    plt.plot(X_train[index_train],y_train_pred[index_train], color='lightcoral', label='Predicción de la regresión');\n",
    "    plt.plot(X, y_real, color='green', linewidth=3, label='Función real',alpha=0.2);    \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left');\n",
    "    plt.title('Datos de train');\n",
    "\n",
    "    plt.figure()\n",
    "    sns.scatterplot(x=X_test,y=y_test, marker='*', color='y', edgecolor='none', s=200, label = 'Valores de test');\n",
    "    index = np.argsort(X_test)\n",
    "    plt.plot(X_test[index],y_test_pred[index], color='lightcoral', label='Predicción de la regresión');\n",
    "    plt.plot(X, y_real, color='green', linewidth=3, label='Función real',alpha=0.2);\n",
    "    plt.title('Datos de test');\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left');\n",
    "\n",
    "\n",
    "\n",
    "def pintar_resultados_clasificacion(X_train, y_train, X_test, y_test):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Valores reales Train')\n",
    "    sns.scatterplot(x=X_train[:,0], y=X_train[:, 1], hue=y_train, marker='o', s=80, palette=['c','y'])\n",
    "    plt.legend(title='Clases');\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Predicciones Train')\n",
    "    sns.scatterplot(x=X_train[:,0], y=X_train[:, 1], hue=y_train_pred, marker='o', s=80, palette=['c','y'])\n",
    "    plt.legend(title='Clases');\n",
    "\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Valores reales Test')\n",
    "    sns.scatterplot(x=X_test[:,0], y=X_test[:, 1], hue=y_test, marker='*', s=200, palette=['c','y'])\n",
    "    class_0 = mlines.Line2D([], [], color='c', marker='*', linestyle='None', markersize=7, label='0')\n",
    "    class_1 = mlines.Line2D([], [], color='y', marker='*', linestyle='None', markersize=7, label='1')\n",
    "    plt.legend(title='Clases', handles=[class_0, class_1], loc=\"upper right\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Predicciones Test')\n",
    "    sns.scatterplot(x=X_test[:,0], y=X_test[:, 1], hue=y_test_pred, marker='*', s=200, palette=['c','y'])\n",
    "    class_0 = mlines.Line2D([], [], color='c', marker='*', linestyle='None', markersize=7, label='0')\n",
    "    class_1 = mlines.Line2D([], [], color='y', marker='*', linestyle='None', markersize=7, label='1')\n",
    "    plt.legend(title='Clases', handles=[class_0, class_1], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IFpxPh57xpe"
   },
   "source": [
    "# Regresión \n",
    "\n",
    "En una regresión queremos predecir la tendencia que siguen los datos. Siendo estos datos variables continuas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3fVbVjq7xpf"
   },
   "source": [
    "##  Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7rd5J787xpf"
   },
   "source": [
    "Para ver como funciona la regresión lineal vamos a generar datos sintéticos, así tendremos el valor real que seguiría la función que queremos predecir.\n",
    "\n",
    "En concreto, vamos a predecir los valores y de la función:\n",
    "\n",
    "$y = 1 + 0.5x$\n",
    "\n",
    "Para generar los datos sintéticos usaremos la función base y le añadiremos ruido gausiano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "Yg8p4qoD7xpf",
    "outputId": "1b8c5c00-73da-4249-a25d-87546ebf733e"
   },
   "outputs": [],
   "source": [
    "N = 50\n",
    "#noise = 0.4\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual \n",
    "\n",
    "X = np.linspace(0, 10, N);\n",
    "y_real =  1 + 0.5*X; \n",
    "\n",
    "def visualizar_muestras_con_ruido(noise):\n",
    "    y = 1 + 0.5*X + np.random.normal(0,noise,N) #ruido gaussiano;\n",
    "    sns.scatterplot(x=X,y=y, label='Muestras', marker='o', color='c', edgecolor='none', s=50);\n",
    "    plt.plot(X, y_real, color='green', linewidth=3, label='Función Real',alpha=0.2)\n",
    "    plt.ylim(0,8)\n",
    "    plt.xlim(0,10)\n",
    "    plt.legend(loc=2)\n",
    "    return y \n",
    "    \n",
    "interactive_plot = interactive(visualizar_muestras_con_ruido, noise=(0.0,1.0));\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBIREagv7xpi"
   },
   "source": [
    "Los separamos en train (2/3) y test (1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "uSOI_MXN7xpi",
    "outputId": "2d1f39c8-c7e1-45a4-e3c8-8d3a1d46d0b1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, interactive_plot.result, test_size=0.33, random_state=42)\n",
    "\n",
    "sns.scatterplot(x=X_train, y=y_train, marker='o', color='c', edgecolor='none', s=50, label='train')\n",
    "sns.scatterplot(x=X_test, y=y_test, marker='*', color='y', edgecolor='none', s=200, label='test')\n",
    "plt.legend()\n",
    "plt.title('Train and test split');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "id": "14Vxwsz27xpo",
    "outputId": "ab3ba0c3-ac63-4aa5-9edf-3cfcf9646497"
   },
   "outputs": [],
   "source": [
    "# Declaramos el modelo\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Lo entrenamos\n",
    "lr.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Pintamos la predicción sobre los datos\n",
    "y_train_pred = lr.predict(X_train.reshape(-1,1))\n",
    "y_test_pred = lr.predict(X_test.reshape(-1, 1))\n",
    "pintar_resultados_regresion(X,y_real, X_train,y_train_pred,X_test,y_test_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZjuDYvXC18s"
   },
   "source": [
    "# <center style='color:lightcoral'> ¡Bien, hemos conseguido buenos resultados! <center>\n",
    "<img src=confeti.gif width=9000px>\n",
    "\n",
    "\n",
    "[Image source](https://static.wixstatic.com/media/0f206d_61c24eba71944a58869c4b6f160b2ca1~mv2.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero... que pasaría si tenemos datos no lineales?\n",
    "\n",
    "Vamos a generar datos sintéticos no lineales para ver que pasa.\n",
    "\n",
    "Esta vez siguiendo la función $y=sin(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "rPbPdlKL7xpr",
    "outputId": "8fb05727-5ca2-4537-a6d4-f77f3ee2e4af"
   },
   "outputs": [],
   "source": [
    "N = 50 # number of data points\n",
    "noise = 0.2\n",
    "\n",
    "X = np.linspace(0, 4*np.pi, N)\n",
    "y_real = np.sin(X) \n",
    "\n",
    "np.random.seed(0) \n",
    "y =np.sin(X)  + np.random.normal(0,noise,N)\n",
    "sns.scatterplot(x=X, y=y, label='Muestras', marker='o', color='c', edgecolor='none', s=50);\n",
    "plt.plot(X, y_real, color='green', linewidth=3, label='Función real',alpha=0.2);\n",
    "plt.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "94X83G1w7xpt"
   },
   "source": [
    "Separamos los datos en train (2/3) y test (1/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "kBwmPPm47xpt",
    "outputId": "381275ae-1ff1-4470-90fc-b1e23bc30da6"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#print(X_train.shape, X_test.shape)\n",
    "sns.scatterplot(x=X_train, y=y_train, marker='o', color='c', edgecolor='none', s=50, label='train')\n",
    "sns.scatterplot(x=X_test, y=y_test, marker='*', color='y', edgecolor='none', s=200, label='test')\n",
    "plt.legend();\n",
    "plt.title('Train and test split');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6NXK4_fIYqj"
   },
   "source": [
    "Entrenamos el modelo con los datos nuevos y predecimos el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "ABSDVLUj7xpw",
    "outputId": "5c9f3259-aafd-414e-a4d7-50f6251f5c48"
   },
   "outputs": [],
   "source": [
    "# Declaramos el modelo\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Lo entrenamos\n",
    "lr.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# Pintamos la predicción sobre los datos\n",
    "y_train_pred = lr.predict(X_train.reshape(-1, 1))\n",
    "\n",
    "y_test_pred = lr.predict(X_test.reshape(-1, 1))\n",
    "\n",
    "print('Mean squared error: ', mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "pintar_resultados_regresion(X,y_real, X_train,y_train_pred,X_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gvzk6AZMD1RP"
   },
   "source": [
    "Los resultados no son tan buenos...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9Mz2oQs7xpx"
   },
   "source": [
    "## Regresión polinómica\n",
    "\n",
    "La regresión lineal no es suficientemente compleja como para poder predecir los datos de nuestra función. Necesitamos maquinaria más potente. \n",
    "\n",
    "Para solucionar este problema vamos a utilizar una regresión polinómica. O lo que es lo mismo: vamos a aplicar una transformación polinómica a nuestros datos y luego vamos a aplicar una regresión lineal sobre los datos transformados. \n",
    "\n",
    "$Transformación(x) = \\hat{x} = constante + x + x^2 + x^3 + ... x^{n - 1}$\n",
    "\n",
    "$Regresión\\_lineal(\\hat{x}) = Regresión\\_lineal(x + x^2 + x^3 + ... x^{n-1}) = Regresión\\_polinómica(x)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion(n=1):\n",
    "    poli_transform = PolynomialFeatures(n)\n",
    "    X_poli_train = poli_transform.fit_transform(X_train.reshape(-1, 1))\n",
    "    X_poli_test = poli_transform.transform(X_test.reshape(-1, 1))\n",
    "\n",
    "    model =  LinearRegression()\n",
    "\n",
    "    model.fit(X_poli_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_poli_train)\n",
    "    y_test_pred = model.predict(X_poli_test)\n",
    "    pintar_resultados_regresion(X,y_real, X_train,y_train_pred,X_test,y_test_pred)\n",
    "    print('Mean squared error:', mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "    \n",
    "interactive_plot = interactive(prediccion, n=(0,10,1));\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un polinómio de grado **n** aproxima bastante bien nuestra función. ¿Cuál creéis que es? Podéis votar [aquí](https://www.menti.com/62jarbciy7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PErMHMGl7xpz"
   },
   "source": [
    "# Clasificación\n",
    "\n",
    "Ahora vamos a ver como trabajaríamos con un problema de clasificación. \n",
    "\n",
    "Esta vez nuestros datos van a tener dos dimensiones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G4e5jvhWBZC1"
   },
   "source": [
    "## Regresión Logística\n",
    "\n",
    "A pesar de su nombre, la regresión logística es un modelo de clasificación. \n",
    "\n",
    "Este modelo es muy parecido a la regresión lineal.\n",
    "\n",
    "La única diferencia es que al resultado de la regresión lineal le aplicamos una función sigmoide. De esta forma, a partir de un resultado continuo obtenemos dos clases. \n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/1280px-Logistic-curve.svg.png width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNmT5qaK7xp0"
   },
   "source": [
    "### Con unos datos fáciles\n",
    "\n",
    "Esta vez vamos a intentar clasificar unos datos linealmente separables. \n",
    "\n",
    "Este tipo de datos no son comunes en la vida real, pero lo vamos a utilizar como ejemplo. \n",
    "\n",
    "Estos datos tienen dos dimensiones, cada punto tendrá un valor para el eje horizontal y otro para el eje vertical.\n",
    "\n",
    "Cada punto corresponderá con una clase, esta clase va a ser lo que queremos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "LbKi99NR7xp0",
    "outputId": "ec27e4ad-2e42-405d-85a5-ff3e32dd506a"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 500\n",
    "NOISE = 0\n",
    "N_VARIABLES = 2\n",
    "\n",
    "X, y = make_classification(n_samples=N_SAMPLES, n_features=N_VARIABLES, n_redundant=0, n_informative=N_VARIABLES,\n",
    "                               random_state=1, n_clusters_per_class=1, class_sep=2-NOISE)\n",
    "\n",
    "#print(X[:4], y[:4])\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, marker='o', palette=['c','y'], s=80);\n",
    "plt.legend(title='Clases');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "VXh4OXWk7xp2",
    "outputId": "d23caea5-208f-42d5-bcbf-843ad734b673"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "pintar_datos_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizamos una regresión logística para clasificar este tipo de datos vemos un muy buen resultado.\n",
    "\n",
    "¡Nuestro modelo ha acertado para todas las muestras!\n",
    "\n",
    "Ahora vamos a ver que pasa si añadimos ruido a los datos. ¿Funciona igual de bien?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "pufyHkkg7xp5",
    "outputId": "c9fb318a-47c9-4c62-f02a-4224d5cd7ba6"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "accuracy_score = lr.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))\n",
    "\n",
    "pintar_resultados_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfPji3ttBguO"
   },
   "source": [
    "### Con datos un poco más difíciles\n",
    "\n",
    "Vamos a probar que pasa con unos datos un poco más complicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "ZLh_MXVD9Iwu",
    "outputId": "a09aa44d-d96c-46ae-98a9-1d684270dc16"
   },
   "outputs": [],
   "source": [
    "ruido = 0.1\n",
    "\n",
    "X, y= make_moons(n_samples=N_SAMPLES, noise=ruido, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "pintar_datos_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues no tenemos tan buenos resultados. \n",
    "\n",
    "Esto pasa por que estamos intentando clasificar dos grupos no linealmente separables con un modelo lineal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "HW2IsMiwBJIl",
    "outputId": "1e6c5186-eee7-47c8-8d11-30483a9854fd"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "accuracy_score = lr.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))\n",
    "\n",
    "pintar_resultados_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con unos datos aun más complicados? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "z0bqjIGRBrUB",
    "outputId": "3e71a21a-f3b1-44a2-c226-10c99172b44d"
   },
   "outputs": [],
   "source": [
    "X, y= make_circles(n_samples=N_SAMPLES, noise=ruido, factor=0.5, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "pintar_datos_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues tenemos un desastre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "GMkOB86rB5GP",
    "outputId": "fa0dbe63-e708-4ac8-851c-3455e1b53156"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "accuracy_score = lr.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))\n",
    "\n",
    "pintar_resultados_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEj_mL60DQ3M"
   },
   "source": [
    "Para datos no linealmente separables vamos a tener que: \n",
    "* Transformarlos no linealmente, como hicimos en el ejemplo de regresión.\n",
    "* Utilizar un modelo no lineal. \n",
    "\n",
    "Ahora vamos a ver como se comportaría un modelo no lineal. \n",
    "\n",
    "## K-Nearest Neighbors(KNN)\n",
    "\n",
    "Para clasificar una muestra por knn se busca las k muestras más parecidas a esta y se le asigna la clase más común dentro de estas muestras.\n",
    "\n",
    "Para este caso concreto mediremos como de parecidas son dos muestras utilizando la distancia euclídea, pero el concepto de \"parecido\" se puede definir como queramos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=knn.gif width=500px>\n",
    "\n",
    "[Image source](https://www.newtechdojo.com/k-nearest-neighbor-algorithm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "tmkX5gKHFg5G",
    "outputId": "0928f78f-3cb8-42e5-c119-b61994bdc47a"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=N_SAMPLES, n_features=N_VARIABLES, n_redundant=0, n_informative=N_VARIABLES,\n",
    "                               random_state=1, n_clusters_per_class=1, class_sep=2-NOISE)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, )\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "accuracy_score = knn.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))\n",
    "\n",
    "pintar_resultados_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "ITqoUfvRDV_l",
    "outputId": "18f2f0b7-e21d-447b-be2e-8b7e641195dc"
   },
   "outputs": [],
   "source": [
    "ruido = 0.1\n",
    "\n",
    "X, y= make_moons(n_samples=N_SAMPLES, noise=ruido, random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, )\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "accuracy_score = knn.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))\n",
    "\n",
    "pintar_resultados_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "colab_type": "code",
    "id": "NTTS_Zx9FxGr",
    "outputId": "6c3a5990-c090-426c-b1d6-22a071105b39"
   },
   "outputs": [],
   "source": [
    "X, y= make_circles(n_samples=N_SAMPLES, noise=ruido, factor=0.5, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, )\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "accuracy_score = knn.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))\n",
    "\n",
    "pintar_resultados_clasificacion(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estos ejemplos hemos trabajado con datos de juguete. Son datos pequeños de los cuales nosotros conocemos la verdadera clase o distribución de las muestras.\n",
    "En el mundo real esto no pasa. Generalmente, no vamos a saber la verdad que se oculta de nuestros datos, y generalmente los datos van a ser más complicados.\n",
    "\n",
    "¿Qué pasa si queremos clasificar imágenes? ¿Qué pasa si queremos clasificar texto? Estos datos son mucho más complicados y necesitan más potencia de computación. En la sesión siguiente hablaremos de como se puede utilizar un supercomputador para resolverlos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pima Diabetes dataset\n",
    "\n",
    "Predecir si un paciente tiene diabetes a partir de sus datos clínicos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import os\n",
    "\n",
    "pima = pd.read_csv(os.path.expanduser('./datasets/diabetes.csv'))\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima_variables = pima.iloc[:,:-1]\n",
    "pima_objetivo = pima.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pima_variables, pima_objetivo, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "accuracy_score = lr.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "accuracy_score = knn.score(X_test, y_test)\n",
    "print('Prediction Accuracy: {}'.format( accuracy_score))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sesion 1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
