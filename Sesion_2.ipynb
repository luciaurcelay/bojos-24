{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronals\n",
    "\n",
    "Ahora querremos aprender a clasificar imágenes, a partir de un entrenamiento con imágenes y etiquetas (aprendizaje supervisado). Con esta intención, utilizaremos el módulo de Keras (que utiliza por debajo de TensorFlow de Google). Para poder ver las imágenes, utilizaremos matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datasets, no usar en local, solo para MareNostrum\n",
    "! cp ./datasets/mnist.npz ~/.keras/datasets/\n",
    "! cp ./datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "En el primer experimento utilizaremos el dataset MNIST. MNIST es un dataset de imágenes de números escritos a mano. El objetivo de la tarea es aprender a reconocer los 10 dígitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset from Keras\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "#Load train data, train labels, test data and test labels.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print( \"Nombre d'imatges per entrenament:\", x_train.shape[0])\n",
    "print( \"Nombre d'imatges per avaluació:\", x_test.shape[0])\n",
    "print( \"Tamany de les imatges:\", x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=img/mnist.png width='450px'>\n",
    "\n",
    "[Image source](https://www.researchgate.net/publication/306056875_An_analysis_of_image_storage_systems_for_scalable_training_of_deep_neural_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 60.000 imágenes de 28x28 píxeles. Si fueran imágenes en color, necesitaríamos otra dimensión para representar los 3 canales del color (es decir, 28x28x3, usando los colores primarios rojo, verde y azul o RGB).\n",
    "Visualizamos una de las imágenes del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elige una imagen del conjunto de entrenamiento al azar\n",
    "import random\n",
    "index_imatge = random.randint(1,x_test.shape[0])\n",
    "# Visualización utilizando matplotlib\n",
    "plt.title('Etiqueta es {label}'.format(label=y_train[index_imatge]))\n",
    "plt.imshow(x_train[index_imatge], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para introducir las imágenes en una FNN necesitamos prepararlas. Consideraremos cada pixel de la imagen como una variable independiente, así que convertiremos la imagen en un vector de longitud 784 (28x28). Cada neurona de la primera capa de la FNN tendrá una entrada de 784 valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=img/mnist_reshape.png width='800px'></center>\n",
    "\n",
    "[Image source](https://puture.tistory.com/385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma les imatges a vectors\n",
    "x_train = x_train.reshape(60000, 28*28)\n",
    "#Fem una copia per us posterior\n",
    "original_test = copy.deepcopy(x_test)\n",
    "x_test = x_test.reshape(10000, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se recomienda normalizar los datos. En estos momentos, los valores del vector son números naturales entre 0 (negro) y 255 (blanco). La red aprenderá más fácilmente si normalizamos estos valores en el rango [0,1] usando decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fragment del vector pre-normalització:\", x_train[0, 201:206])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "print(\"Fragment del vector post-normalització:\", x_train[0, 201:206])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También debemos ajustar las etiquetas asociadas a las imágenes a las necesidades de la FNN. La etiqueta en este caso es un dato 'categórico', es decir: puede tomar un valor de un conjunto de valores finito en los que no existe orden. Aunque en este problema parece haber un orden entre las etiquetas, este orden no es relevante de cara a clasificar imágenes.\n",
    "\n",
    "La salida de la red neuronal representa un conjunto de probabilidades de cada imagen. Por ejemplo, la salida:\n",
    "[0, 0, 0, 0, 0.25, 0, 0.5, 0.25, 0, 0]\n",
    "Indica una probabilidad del 25% de las etiquetas '4' y '7' y una probabilidad del 50% de la etiqueta '6'.\n",
    "Para poder calcular el error de la red en su predicción, utilizamos una representación análoga de las etiquetas. Así pues una imagen con etiqueta '6' tendrá la siguiente representación:\n",
    "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "Y el error de la red se calculará como la diferencia entre ambos vectores. Este tipo de representación se llama one-hot vector encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=img/one_hot.PNG width='500px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import to_categorical\n",
    "print(\"Format original:\",y_train[0])\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "print(\"Format one-hot:\",y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red neuronal Feed-forward\n",
    "\n",
    "Ahora, ya podremos pasar a definir nuestra red. Empecemos con una red neuronal de dos capas con 32 y 16 neuronas respectivamente. Todas con función de activación ReLU. La capa de salida tendrá 10 neuronas (1 por clase/etiqueta), usando la función softmax para obtener probabilidades por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(32,activation='relu',input_shape=(784,)))\n",
    "nn.add(Dense(16,activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nos queda definir el optimizador y sus parámetros. Optimizaremos utilizando 'Stochastic Gradient Descent' (sgd), evaluando nuestro error con la función 'Categorical Crossentropy' (que es la adecuada cuando utilizamos softmax), y optimizaremos para mejorar la 'accuracy' del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=img/categorical_cross_entropy.png width='400px'>\n",
    "<img src=img/loss.png width='400px'>\n",
    "\n",
    "\n",
    "Fuente de las imágenes y más información sobre la 'cross-entropy' [aquí](https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos empezar a entrenar la red con los datos de entrenamiento. Lo haremos en lotes de 128 imágenes (batch size). Cuando hayamos visto todas las imágenes (1 epoch), volveremos a empezar. En total, pasaremos cada imagen 10 veces por la red (10 epochs).\n",
    "\n",
    "En el output vemos en qué epoch estamos, el error cometido en esa epoch (loss) que la red pretende minimizar, y la precisión obtenida (accuracy) en los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start training\n",
    "nepochs=10\n",
    "history = nn.fit(x_train,y_train,batch_size=128,epochs=nepochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendimiento en el conjunto de entrenamiento es suficientemente bueno (91%-92% de precisión). Pero falta por ver si éste se mantiene en los datos de evaluación. Así veremos si el modelo entrenado generaliza bien a nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque los números no son los mismos, parece que la red generaliza bastante bien.\n",
    "Ahora vamos a visualizar el entrenamiento con las curvas de precisión y error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plot = plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_plot = plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que la red aprende de forma continuada. También parece que la tendencia era a mejorar, así que quizás sería buena idea darle más epochs para obtener mejores resultados.\n",
    "\n",
    "Por último, vamos a ver la relación de aciertos y errores, usando una matriz de confusión. La matriz de confusión muestra las predicciones hechas junto a las etiquetas reales. Permite ver dónde se han cometido los errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "#Predir el test i contrastar-lo amb els valors reals.\n",
    "Y_pred = nn.predict(x_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(np.argmax(y_test,axis=1), y_pred), index = range(10), columns = range(10))\n",
    "plt.figure(figsize = (10,7))\n",
    "ax = sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, cmap=\"YlGnBu\", fmt='g');\n",
    "plt.ylabel(\"Etiqueta real\")\n",
    "plt.xlabel(\"Etiqueta predita\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los errores parecen estar muy repartidos. La etiqueta peor predicho es el 5, que muy a menudo se clasifica como la etiqueta 3.\n",
    "\n",
    "Vamos a ver ejemplos de errores cometidos. Muchos son errores razonables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [(i, predit, np.argmax(real)) for i,(predit, real) in enumerate(zip(y_pred, y_test)) if predit!=np.argmax(real)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_error = random.randint(0,len(errors))\n",
    "error_a_analitzar = errors[index_error]\n",
    "plt.title(\"Predit:\"+str(error_a_analitzar[1])+\"; Real:\"+str(error_a_analitzar[2]))\n",
    "plt.imshow(original_test[error_a_analitzar[0]], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede verse, los errores son las imágenes especialmente problemáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR DATASET\n",
    "\n",
    "Ahora vamos a trabajar con un problema algo más complicado. Imágenes en color representando varios objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from tensorflow.python.keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el dataset CIFAR10, que tiene clases de animales y vehículos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import cifar10\n",
    "\n",
    "(original_x_train, y_train), (original_x_test, y_test) = cifar10.load_data()\n",
    "# Located in ~/.keras/datasets and probably need untarred\n",
    "x_train = copy.deepcopy(original_x_train)\n",
    "x_test = copy.deepcopy(original_x_test)\n",
    "print( \"Número d'imatges per entrenament:\", x_train.shape[0])\n",
    "print( \"Número d'imatges per avaluació:\", x_test.shape[0])\n",
    "print( \"Tamany de les imatges:\", x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, las imágenes tienen profundidad, ya que tenemos canal de color. Habrá que adaptar el código.\n",
    "\n",
    "Para entender mejor las clases, https://www.cs.toronto.edu/~kriz/cifar.html tiene una guía que nos transforma la etiqueta numérica en la clase en palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map=['airplane','automobile', 'bird', 'cat','deer','dog','frog','horse','ship','truck']\n",
    "import random\n",
    "index_imatge = random.randint(0,9)\n",
    "plt.title(\"L'etiqueta és {label}\".format(label=label_map[y_train[index_imatge][0]]))\n",
    "plt.imshow(x_train[index_imatge], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepararemos los datos al igual que antes. Ahora, los vectores serán de 3,072 posiciones (32x32x3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(50000, 32*32*3)\n",
    "x_test = x_test.reshape(10000, 32*32*3)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(32, activation='relu', input_shape=(32*32*3,)))\n",
    "nn.add(Dense(16, activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "nn.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=20\n",
    "history = nn.fit(x_train,y_train,batch_size=128,epochs=nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plot = plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_plot = plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados no son tan buenos en este problema. Alrededor del 40%.\n",
    "¿Puede extraer cuáles son las clases del test donde más se equivoca?\n",
    "¿Puede ver las imágenes erróneas?\n",
    "¿Puede mejorar la accuracy de test?\n",
    "¿Y cuánto la puede mejorar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tornem a les slides!\n",
    "<img src=\"img/end_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocessing es similar al anterior, pero las neuronas convolucionales de la primera capa necesitan las entradas en 3 dimensiones. El orden de las dimensiones depende del backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "img_rows, img_cols, channels = 32, 32, 3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestra red. Volveremos a tener tres capas ocultas de 32, 16 y 16 neuronas, y una de salida que será una softmax de 10 posiciones.\n",
    "\n",
    "A diferencia de que antes, sin embargo, las dos primeras capas serán convolucionales. Ambas usarán kernels (filtros) de 2 por 2. Después de cada capa convolucional, haremos un 'pooling', cogiendo el valor máximo de cada cuatro píxeles (para reducir las dimensiones de la salida de la capa). Por último, entre la segunda capa convolucional y la primera capa no convolucional (fully connected), deberemos aplanar los datos a un vector (como antes hemos hecho en el preprocessing).\n",
    "\n",
    "Volveremos a utilizar los mismos parámetros por optimización que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense \n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Conv2D(filters=32, kernel_size=(2, 2), input_shape=input_shape, activation='relu', padding='same', strides=(2,2)))\n",
    "nn.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
    "nn.add(Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=16))\n",
    "nn.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(16, activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "nn.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#print(nn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que ahora, al entrenar, nos dejamos un 15% de imágenes por validación. Por tanto, también nos aparecerán la loss y la accuracy de la validación aparte. El entrenamiento de la nueva red tardará algo más que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=10\n",
    "history = nn.fit(x_train,y_train,batch_size=128, epochs=nepochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, realizaremos un estudio sobre nuestros propios resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plot = plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_plot = plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo mejoraría las redes? ¿Cuál es el mejor resultado de accuracy en el test que puede obtener?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
