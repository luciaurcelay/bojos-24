{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xarxes neuronals\n",
    "\n",
    "Ara voldrem aprendre a classificar imatges, a partir d'un entrenament amb imatges i etiquetes (aprenentatge supervisat). Amb aquesta intenció, farem servir el mòdul de Keras (que utilitza per sota TensorFlow de Google). Per poder veure les imatges, farem servir matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy datasets, no usar en local, solo para MareNostrum\n",
    "! cp ./datasets/mnist.npz ~/.keras/datasets/\n",
    "! cp ./datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el primer experiment usarem el dataset MNIST. MNIST és un dataset d'imatges de números escrits a mà. L'objectiu de la tasca és aprendre a reconèixer els 10 dígits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset from Keras\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "#Load train data, train labels, test data and test labels.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print( \"Nombre d'imatges per entrenament:\", x_train.shape[0])\n",
    "print( \"Nombre d'imatges per avaluació:\", x_test.shape[0])\n",
    "print( \"Tamany de les imatges:\", x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=mnist.png width='450px'>\n",
    "\n",
    "[Image source](https://www.researchgate.net/publication/306056875_An_analysis_of_image_storage_systems_for_scalable_training_of_deep_neural_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenim 60,000 imatges de 28x28 píxels. Si fossin imatges en color, necesitariem una altra dimensió per representar els 3 canals del color (és a dir, 28x28x3, usant els colors primaris vermell, verd i blau, o RGB). \n",
    "Visualitzem una de les imatges del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tria una imatge del conjunt d'entrenament al atzar\n",
    "import random\n",
    "index_imatge = random.randint(1,x_test.shape[0])\n",
    "#Visualitza usant matplotlib\n",
    "plt.title('Etiqueta es {label}'.format(label=y_train[index_imatge]))\n",
    "plt.imshow(x_train[index_imatge], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per introduïr les imatges a una FNN ens cal preparar-les. Considerarem cada pixel de la imatge com una variable independent, aixi que convertirem la imatge en un vector de longitud 784 (28x28). Cada neurona de la primera capa de la FNN tindrá una entrada de 784 valors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=mnist_reshape.png width='800px'></center>\n",
    "\n",
    "[Image source](https://puture.tistory.com/385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforma les imatges a vectors\n",
    "x_train = x_train.reshape(60000, 28*28)\n",
    "#Fem una copia per us posterior\n",
    "original_test = copy.deepcopy(x_test)\n",
    "x_test = x_test.reshape(10000, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També és recomanat normalitzar les dades. Ara mateix, els valors del vector són nombres naturals entre 0 (negre) i 255 (blanc). La xarxa aprendrà més fàcilment si normalitzem aquests valors al rang [0,1] usant decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fragment del vector pre-normalització:\", x_train[0, 201:206])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "print(\"Fragment del vector post-normalització:\", x_train[0, 201:206])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També cal que ajustem les etiquetes associades a les imatges a les necessitats de la FNN. L'etiqueta en aquest cas és una dada 'categòrica', és a dir: pot prendre un valor d'un conjunt de valors finit en què no existeix ordre. Malgrat que en aquest problema sembla que n'hi ha un ordre entre les etiquetes, aquest ordre no és rellevant de cara a classificar imatges.\n",
    "\n",
    "La sortida de la xarxa neuronal representa un conjunt de probabilitats per a cada imatge. Per exemple, la sortida:\n",
    "[0, 0, 0, 0, 0.25, 0, 0.5, 0.25, 0, 0]\n",
    "Indica una probabilitat del 25% de les etiquetes '4' i '7', i una probabilitat del 50% de l'etiqueta '6'.\n",
    "Per poder calcular l'error de la xarxa en la seua predicció, usem una representació anàloga de les etiquetes. Així doncs una imatge amb etiqueta '6' tindrà la següent representació:\n",
    "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
    "I l'error de la xarxa és calcularà com la diferència entre ambdós vectors. Aquest tipus de representació s'anomena one-hot vector encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=one_hot.PNG width='500px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import to_categorical\n",
    "print(\"Format original:\",y_train[0])\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "print(\"Format one-hot:\",y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarxa neuronal Feed-forward\n",
    "\n",
    "Ara ja podrem passar a definir la nostra xarxa. Comencem amb una xarxa neuronal de dues capes amb 32 i 16 neurones respectivament. Totes amb funció d'activació ReLU. La capa de sortida tindrà 10 neurones (1 per classe/etiqueta), usant la funció softmax per a obtenir probabilitats per classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(32,activation='relu',input_shape=(784,)))\n",
    "nn.add(Dense(16,activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ens queda definir l'optimitzador i els seus paràmetres. Optimitzarem fent servir 'Stochastic Gradient Descent' (sgd), avaluant el nostre error amb la funció 'Categorical Crossentropy' (que és l'adequada quan fem servir softmax), i optimitzarem per millorar la 'accuracy' del model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=categorical_cross_entropy.png width='400px'>\n",
    "<img src=loss.png width='400px'>\n",
    "\n",
    "\n",
    "Font de les imatges i més informació sobre la 'cross-entropy' [aquí](https://towardsdatascience.com/cross-entropy-for-classification-d98e7f974451)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ja podem començar a entrenar la xarxa amb les dades d'entrenament. Ho farem en lots de 128 imatges (batch size). Quan hàgim vist totes les imatges (1 epoch), tornarem a començar. En total, passarem cada imatge 10 vegades per la xarxa (10 epochs).\n",
    "\n",
    "A l'output veiem en quina epoch estem, l'error comès en aquesta epoch (loss) que la xarxa pretén minimitzar, i la precisió obtinguda (accuracy) en les dades d'entrenament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start training\n",
    "nepochs=10\n",
    "history = nn.fit(x_train,y_train,batch_size=128,epochs=nepochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El rendiment al conjunt d'entrenament és prou bo (91%-92% de precisió). Però falta per veure si aquest es manté en les dades d'avaluació. Així veurem si el model entrenat generalitza bé a noves dades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgrat que els nombres no son els mateixos, sembla que la xarxa generalitza prou bé. \n",
    "Ara anem a visualitzar el entrenament amb les corves de precisió i error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plot = plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_plot = plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sembla que la xarxa a aprés d'una manera continuada. També sembla que la tendència era a millorar, així que potser seria bona idea donar-li més epochs per a obtenir millors resultats.\n",
    "\n",
    "Finalment, anem a veure la relació d'encerts i errors, usant una matriu de confusió. La matriu de confusió mostra les prediccions fetes junt amb les etiquetes reals. Permet veure on s'han comès els errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "#Predir el test i contrastar-lo amb els valors reals.\n",
    "Y_pred = nn.predict(x_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(np.argmax(y_test,axis=1), y_pred), index = range(10), columns = range(10))\n",
    "plt.figure(figsize = (10,7))\n",
    "ax = sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 8}, cmap=\"YlGnBu\", fmt='g');\n",
    "plt.ylabel(\"Etiqueta real\")\n",
    "plt.xlabel(\"Etiqueta predita\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sembla que els errors estan molt repartits. L'etiqueta pitjor predita és el 5, que molt sovint es classifica com l'etiqueta 3.\n",
    "\n",
    "Anem a veure exemples d'errors comesos. Molts són errors raonables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [(i, predit, np.argmax(real)) for i,(predit, real) in enumerate(zip(y_pred, y_test)) if predit!=np.argmax(real)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index_error = random.randint(0,len(errors))\n",
    "error_a_analitzar = errors[index_error]\n",
    "plt.title(\"Predit:\"+str(error_a_analitzar[1])+\"; Real:\"+str(error_a_analitzar[2]))\n",
    "plt.imshow(original_test[error_a_analitzar[0]], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com podem veure, els errors són les imatges especialment problemàtiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR DATASET\n",
    "\n",
    "\n",
    "Ara anem a treballar amb un problema una mica més complicat. Imatges en color representant diversos objectes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from tensorflow.python.keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importem el dataset CIFAR10, que té classes d'animals i vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.datasets import cifar10\n",
    "\n",
    "(original_x_train, y_train), (original_x_test, y_test) = cifar10.load_data()\n",
    "# Located in ~/.keras/datasets and probably need untarred\n",
    "x_train = copy.deepcopy(original_x_train)\n",
    "x_test = copy.deepcopy(original_x_test)\n",
    "print( \"Número d'imatges per entrenament:\", x_train.shape[0])\n",
    "print( \"Número d'imatges per avaluació:\", x_test.shape[0])\n",
    "print( \"Tamany de les imatges:\", x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas les imatges tenen profunditat, ja que tenim canal de color. Caldrà adaptar el codi.\n",
    "\n",
    "Per entendre millor les classes, https://www.cs.toronto.edu/~kriz/cifar.html té una guía que ens transforma la etiqueta numèrica en la classe en paraules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map=['airplane','automobile', 'bird', 'cat','deer','dog','frog','horse','ship','truck']\n",
    "import random\n",
    "index_imatge = random.randint(0,9)\n",
    "plt.title(\"L'etiqueta és {label}\".format(label=label_map[y_train[index_imatge][0]]))\n",
    "plt.imshow(x_train[index_imatge], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepararem les dades igual que abans. Ara els vectors seran de 3,072 posicions (32x32x3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(50000, 32*32*3)\n",
    "x_test = x_test.reshape(10000, 32*32*3)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Dense(32, activation='relu', input_shape=(32*32*3,)))\n",
    "nn.add(Dense(16, activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "nn.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=20\n",
    "history = nn.fit(x_train,y_train,batch_size=128,epochs=nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plot = plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_plot = plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)], fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els resultats no son tan bons en aquest problema. Al voltant del 40%.\n",
    "Podeu extreure quines són les classes del test on més s'equivoca?\n",
    "Podeu veure les imatges erronies?\n",
    "Podeu millorar la accuracy de test?\n",
    "I quant la podeu millorar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tornem a les slides!\n",
    "<img src=\"end_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarxes convolucionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocessing és similar al que hem fet abans, però les neurones convolucionals de la primera capa necessiten les entrades en 3 dimensions. L'ordre de les dimensions depèn del backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "img_rows, img_cols, channels = 32, 32, 3\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definim la nostra xarxa. Tornarem a tenir tres capes ocultes de 32, 16 i 16 neurones, i una de sortida que serà una softmax de 10 posicions.\n",
    "\n",
    "A diferència que abans, però, les dues primeres capes seran convolucionals. Ambdues usaran kernels (filtres) de 2 per 2. Després de cada capa convolucional, farem un 'pooling', agafant el valor màxim de cada quatre píxels (per reduir les dimensions de la sortida de la capa). Per últim, entre la segona capa convolucional i la primera capa no convolucional (fully connected), haurem d'aplanar les dades a un vector (com abans hem fet en el preprocessing).\n",
    "\n",
    "Tornarem a usar els mateixos paràmetres per optimització que abans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense \n",
    "\n",
    "nn = Sequential()\n",
    "nn.add(Conv2D(filters=32, kernel_size=(2, 2), input_shape=input_shape, activation='relu', padding='same', strides=(2,2)))\n",
    "nn.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
    "nn.add(Conv2D(kernel_size=(2, 2), padding='same', strides=(2, 2), filters=16))\n",
    "nn.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(16, activation='relu'))\n",
    "nn.add(Dense(10, activation='softmax'))\n",
    "nn.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#print(nn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notem que ara, en entrenar, ens deixem un 15% d'imatges per validació. Per tant, també ens apareixeran la loss i la accuracy de la validació a part. L'entrenament de la nova xarxa trigarà una mica més que abans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs=10\n",
    "history = nn.fit(x_train,y_train,batch_size=128, epochs=nepochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nou, farem un estudi sobre els nostres propis resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plot = plt.figure(1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_plot = plt.figure(2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks([x for x in range(nepochs)], [x+1 for x in range(nepochs)])\n",
    "plt.legend(['train','val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com milloraríeu les xarxes? Quin és el millor resultat d'accuracy en el test que podeu obtenir?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
